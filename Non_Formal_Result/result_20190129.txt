zhengzhongliang@dauphin:~/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity$ ./experiments.sh
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 1
word embd: 0
char embd: 0
[dynet] random seed: 1
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: 1.0131685584783554 W std: 0.21607817256790918
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.183297
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964698	Recall: 0.975312F1: 0.969976
Neg Count: 1	N Samples: 12655	Precision: 0.852573	Recall: 0.877041F1: 0.864634
Neg Count: 2	N Samples: 1718	Precision: 0.912736	Recall: 0.853363	F1: 0.882051
Neg Count: 3	N Samples: 168	Precision: 0.872093	Recall: 0.882353	F1: 0.877193
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9577000592768227
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 2.864047895411204 W std: 0.4847922266792119
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.078142
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.988009	Recall: 0.989160F1: 0.988584
Neg Count: 1	N Samples: 12655	Precision: 0.945799	Recall: 0.949777F1: 0.947784
Neg Count: 2	N Samples: 1718	Precision: 0.974886	Recall: 0.941566	F1: 0.957936
Neg Count: 3	N Samples: 168	Precision: 0.964706	Recall: 0.964706	F1: 0.964706
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9839363172696506
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.5162608777172863 W std: 0.5428420815096905
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.061344
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.991840	Recall: 0.991464F1: 0.991652
Neg Count: 1	N Samples: 12655	Precision: 0.965827	Recall: 0.957942F1: 0.961868
Neg Count: 2	N Samples: 1718	Precision: 0.983012	Recall: 0.957001	F1: 0.969832
Neg Count: 3	N Samples: 168	Precision: 0.987952	Recall: 0.964706	F1: 0.976190
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9882956511364315
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.22965276427567 W std: 0.5491734453526042
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.059865
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992168	Recall: 0.992114F1: 0.992141
Neg Count: 1	N Samples: 12655	Precision: 0.967082	Recall: 0.959426F1: 0.963239
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889061195276154
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.212566607631743 W std: 0.5497220798900141
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.059558
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992168	Recall: 0.992195F1: 0.992182
Neg Count: 1	N Samples: 12655	Precision: 0.966866	Recall: 0.960168F1: 0.963505
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889666853537221
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.2170863207429647 W std: 0.5497163128707712
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.059473
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992195	Recall: 0.992195F1: 0.992195
Neg Count: 1	N Samples: 12655	Precision: 0.966866	Recall: 0.960168F1: 0.963505
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889784817977957
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.2170626055449247 W std: 0.5497157392460225
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.059468
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992195	Recall: 0.992195F1: 0.992195
Neg Count: 1	N Samples: 12655	Precision: 0.967107	Recall: 0.960168F1: 0.963625
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889902785232898
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.2170574069023132 W std: 0.5497157428161454
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.059467
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992195	Recall: 0.992195F1: 0.992195
Neg Count: 1	N Samples: 12655	Precision: 0.967107	Recall: 0.960168F1: 0.963625
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889902785232898
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.2170574069023132 W std: 0.5497157428161454
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.059467
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992195	Recall: 0.992195F1: 0.992195
Neg Count: 1	N Samples: 12655	Precision: 0.967107	Recall: 0.960168F1: 0.963625
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889902785232898
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.2170574069023132 W std: 0.5497157428161454
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.059467
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992195	Recall: 0.992195F1: 0.992195
Neg Count: 1	N Samples: 12655	Precision: 0.967107	Recall: 0.960168F1: 0.963625
Neg Count: 2	N Samples: 1718	Precision: 0.984163	Recall: 0.959206	F1: 0.971524
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9889902785232898
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_1_wordEmbd_0_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 1
word embd: 0
char embd: 1
[dynet] random seed: 1
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: 1.0131685584783554 W std: 0.21607817256790918
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.183638
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.963795	Recall: 0.976776F1: 0.970242
Neg Count: 1	N Samples: 12655	Precision: 0.846914	Recall: 0.869124F1: 0.857875
Neg Count: 2	N Samples: 1718	Precision: 0.905312	Recall: 0.864388	F1: 0.884377
Neg Count: 3	N Samples: 168	Precision: 0.925926	Recall: 0.882353	F1: 0.903614
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9573918810099
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.047529684379697 W std: 0.4480120128968174
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.081119
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.988777	Recall: 0.988401F1: 0.988589
Neg Count: 1	N Samples: 12655	Precision: 0.944417	Recall: 0.933201F1: 0.938776
Neg Count: 2	N Samples: 1718	Precision: 0.974742	Recall: 0.936053	F1: 0.955006
Neg Count: 3	N Samples: 168	Precision: 0.976190	Recall: 0.964706	F1: 0.970414
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9830524657468851
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.0562803012362565 W std: 0.4958263365183777
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.062465
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.991845	Recall: 0.992033F1: 0.991939
Neg Count: 1	N Samples: 12655	Precision: 0.959311	Recall: 0.950767F1: 0.955020
Neg Count: 2	N Samples: 1718	Precision: 0.980594	Recall: 0.947078	F1: 0.963545
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9877603607472621
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.059766909223981 W std: 0.501848448537398
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.060337
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992385	Recall: 0.992412F1: 0.992399
Neg Count: 1	N Samples: 12655	Precision: 0.961567	Recall: 0.953241F1: 0.957386
Neg Count: 2	N Samples: 1718	Precision: 0.981756	Recall: 0.949283	F1: 0.965247
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9884278590346209
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.0561707001179457 W std: 0.5023525369721399
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.059950
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992412F1: 0.992452
Neg Count: 1	N Samples: 12655	Precision: 0.961567	Recall: 0.953241F1: 0.957386
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9884868224823126
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.055459608673118 W std: 0.5023281639547181
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.059842
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992466F1: 0.992480
Neg Count: 1	N Samples: 12655	Precision: 0.961807	Recall: 0.953241F1: 0.957505
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9885227516762509
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.055734357214533 W std: 0.5023275222122052
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.059834
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992466F1: 0.992480
Neg Count: 1	N Samples: 12655	Precision: 0.961817	Recall: 0.953488F1: 0.957634
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9885348190744342
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.055724781821482 W std: 0.5023275230647012
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.059834
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992466F1: 0.992480
Neg Count: 1	N Samples: 12655	Precision: 0.961817	Recall: 0.953488F1: 0.957634
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9885348190744342
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.0557247982360423 W std: 0.5023275230638519
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.059834
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992466F1: 0.992480
Neg Count: 1	N Samples: 12655	Precision: 0.961817	Recall: 0.953488F1: 0.957634
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9885348190744342
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.0557247982360423 W std: 0.5023275230638519
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.059834
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.992493	Recall: 0.992466F1: 0.992480
Neg Count: 1	N Samples: 12655	Precision: 0.961817	Recall: 0.953488F1: 0.957634
Neg Count: 2	N Samples: 1718	Precision: 0.982877	Recall: 0.949283	F1: 0.965788
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9885348190744342
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_1_wordEmbd_0_charEmbd_1.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 1
word embd: 1
char embd: 0
[dynet] random seed: 1
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: 0.002105608582496643 W std: 0.21955172234421644
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.324787
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.927878	Recall: 0.960516F1: 0.943915
Neg Count: 1	N Samples: 12655	Precision: 0.683590	Recall: 0.789461F1: 0.732721
Neg Count: 2	N Samples: 1718	Precision: 0.853222	Recall: 0.788313	F1: 0.819484
Neg Count: 3	N Samples: 168	Precision: 0.828947	Recall: 0.741176	F1: 0.782609
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9196099472775626
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.3597261212999 W std: 0.35536985569066754
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.249145
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.950580	Recall: 0.964310F1: 0.957396
Neg Count: 1	N Samples: 12655	Precision: 0.778087	Recall: 0.831024F1: 0.803685
Neg Count: 2	N Samples: 1718	Precision: 0.882214	Recall: 0.825799	F1: 0.853075
Neg Count: 3	N Samples: 168	Precision: 0.887500	Recall: 0.835294	F1: 0.860606
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9398447377438527
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.386588619556278 W std: 0.37804973708583783
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.228623
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.957452	Recall: 0.965340F1: 0.961380
Neg Count: 1	N Samples: 12655	Precision: 0.815290	Recall: 0.849579F1: 0.832081
Neg Count: 2	N Samples: 1718	Precision: 0.900709	Recall: 0.840132	F1: 0.869367
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9466766314340962
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.386561086168513 W std: 0.38217984329856125
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.226022
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.958746	Recall: 0.965475F1: 0.962099
Neg Count: 1	N Samples: 12655	Precision: 0.819957	Recall: 0.851806F1: 0.835578
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9477070645915691
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.388320668891538 W std: 0.38244376875511044
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.225498
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.958976	Recall: 0.965421F1: 0.962188
Neg Count: 1	N Samples: 12655	Precision: 0.820653	Recall: 0.851311F1: 0.835701
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9478033721206364
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.382889081491157 W std: 0.3823609049457714
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.225290
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959003	Recall: 0.965448F1: 0.962215
Neg Count: 1	N Samples: 12655	Precision: 0.820696	Recall: 0.851559F1: 0.835843
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9478396124482018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.3834602943388745 W std: 0.3823585753392822
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.225274
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959003	Recall: 0.965448F1: 0.962215
Neg Count: 1	N Samples: 12655	Precision: 0.820653	Recall: 0.851311F1: 0.835701
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.947827119449062
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.383489486761391 W std: 0.382358574369109
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.225274
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959003	Recall: 0.965448F1: 0.962215
Neg Count: 1	N Samples: 12655	Precision: 0.820653	Recall: 0.851311F1: 0.835701
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.947827119449062
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.383489650557749 W std: 0.3823585743442058
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.225274
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959003	Recall: 0.965448F1: 0.962215
Neg Count: 1	N Samples: 12655	Precision: 0.820653	Recall: 0.851311F1: 0.835701
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.947827119449062
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 5.383489650557749 W std: 0.3823585743442058
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.225274
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959003	Recall: 0.965448F1: 0.962215
Neg Count: 1	N Samples: 12655	Precision: 0.820653	Recall: 0.851311F1: 0.835701
Neg Count: 2	N Samples: 1718	Precision: 0.904028	Recall: 0.841235	F1: 0.871502
Neg Count: 3	N Samples: 168	Precision: 0.915663	Recall: 0.894118	F1: 0.904762
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.947827119449062
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_1_wordEmbd_1_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 1
word embd: 1
char embd: 1
[dynet] random seed: 1
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: 0.002105608582496643 W std: 0.21955172234421644
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.299593
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.944290	Recall: 0.948538F1: 0.946409
Neg Count: 1	N Samples: 12655	Precision: 0.743412	Recall: 0.767689F1: 0.755355
Neg Count: 2	N Samples: 1718	Precision: 0.871375	Recall: 0.761852	F1: 0.812941
Neg Count: 3	N Samples: 168	Precision: 0.857143	Recall: 0.776471	F1: 0.814815
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9247698127572505
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -5.22557390818838 W std: 0.38125537597872516
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.230246
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.954550	Recall: 0.966424F1: 0.960450
Neg Count: 1	N Samples: 12655	Precision: 0.795364	Recall: 0.840426F1: 0.817274
Neg Count: 2	N Samples: 1718	Precision: 0.895363	Recall: 0.830209	F1: 0.861556
Neg Count: 3	N Samples: 168	Precision: 0.876543	Recall: 0.835294	F1: 0.855422
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9440973208368834
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -5.972347512142733 W std: 0.4007364197673485
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.217459
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.960606	Recall: 0.966098F1: 0.963344
Neg Count: 1	N Samples: 12655	Precision: 0.821317	Recall: 0.842652F1: 0.831848
Neg Count: 2	N Samples: 1718	Precision: 0.910394	Recall: 0.840132	F1: 0.873853
Neg Count: 3	N Samples: 168	Precision: 0.878049	Recall: 0.847059	F1: 0.862275
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9484719894447813
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.069257382070646 W std: 0.40535289030257404
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.215757
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961572	Recall: 0.966288F1: 0.963924
Neg Count: 1	N Samples: 12655	Precision: 0.825992	Recall: 0.844384F1: 0.835087
Neg Count: 2	N Samples: 1718	Precision: 0.911589	Recall: 0.841235	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9493476683752957
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.071086567186285 W std: 0.40568215486761183
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.215242
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961962	Recall: 0.966315F1: 0.964134
Neg Count: 1	N Samples: 12655	Precision: 0.825708	Recall: 0.843889F1: 0.834700
Neg Count: 2	N Samples: 1718	Precision: 0.915865	Recall: 0.840132	F1: 0.876366
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9495259507750139
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.067404958652332 W std: 0.4055936062328701
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.215025
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961987	Recall: 0.966288F1: 0.964133
Neg Count: 1	N Samples: 12655	Precision: 0.825624	Recall: 0.843394F1: 0.834414
Neg Count: 2	N Samples: 1718	Precision: 0.916867	Recall: 0.839030	F1: 0.876223
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9494985545522681
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.067449219757691 W std: 0.4055917918661828
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.215010
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961987	Recall: 0.966288F1: 0.964133
Neg Count: 1	N Samples: 12655	Precision: 0.825824	Recall: 0.843394F1: 0.834517
Neg Count: 2	N Samples: 1718	Precision: 0.916867	Recall: 0.839030	F1: 0.876223
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9495098505758066
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.06745761615457 W std: 0.405591790396865
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.215010
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961987	Recall: 0.966288F1: 0.964133
Neg Count: 1	N Samples: 12655	Precision: 0.825824	Recall: 0.843394F1: 0.834517
Neg Count: 2	N Samples: 1718	Precision: 0.916867	Recall: 0.839030	F1: 0.876223
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9495098505758066
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.067456583317835 W std: 0.4055917905707912
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.215010
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961987	Recall: 0.966288F1: 0.964133
Neg Count: 1	N Samples: 12655	Precision: 0.825824	Recall: 0.843394F1: 0.834517
Neg Count: 2	N Samples: 1718	Precision: 0.916867	Recall: 0.839030	F1: 0.876223
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9495098505758066
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -6.067456583317835 W std: 0.4055917905707912
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.215010
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.961987	Recall: 0.966288F1: 0.964133
Neg Count: 1	N Samples: 12655	Precision: 0.825824	Recall: 0.843394F1: 0.834517
Neg Count: 2	N Samples: 1718	Precision: 0.916867	Recall: 0.839030	F1: 0.876223
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
overall f1: 0.9495098505758066
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_1_wordEmbd_1_charEmbd_1.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 2
word embd: 0
char embd: 0
[dynet] random seed: 2
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -4.569457218050957 W std: 0.22415494179833798
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.180321
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.968900	Recall: 0.972602F1: 0.970748
Neg Count: 2	N Samples: 1718	Precision: 0.927294	Recall: 0.857773	F1: 0.891180
Neg Count: 1	N Samples: 12655	Precision: 0.866601	Recall: 0.871103F1: 0.868846
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9591321536592917
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -2.065170376095921 W std: 0.4160595527998621
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.069558
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.990403	Recall: 0.990054F1: 0.990229
Neg Count: 2	N Samples: 1718	Precision: 0.967120	Recall: 0.940463	F1: 0.953605
Neg Count: 1	N Samples: 12655	Precision: 0.957186	Recall: 0.945819F1: 0.951468
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.976471	Recall: 0.976471	F1: 0.976471
overall f1: 0.9857043984630438
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -1.1939058711141115 W std: 0.46578530132473617
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.052876
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993091	Recall: 0.993361F1: 0.993226
Neg Count: 2	N Samples: 1718	Precision: 0.977578	Recall: 0.961411	F1: 0.969427
Neg Count: 1	N Samples: 12655	Precision: 0.974134	Recall: 0.959673F1: 0.966849
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9901696452005442
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9510498626623303 W std: 0.4716246753412022
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.051071
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993714	Recall: 0.993876F1: 0.993795
Neg Count: 2	N Samples: 1718	Precision: 0.977604	Recall: 0.962514	F1: 0.970000
Neg Count: 1	N Samples: 12655	Precision: 0.974699	Recall: 0.962642F1: 0.968633
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9908504216917774
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9287688981276006 W std: 0.47204978897120464
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.050629
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974718	Recall: 0.963384F1: 0.969018
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909589694656488
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9268466043286026 W std: 0.4720452803934695
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.050542
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974962	Recall: 0.963384F1: 0.969139
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909707892508262
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9270014967769384 W std: 0.47204472189464314
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.050537
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974962	Recall: 0.963384F1: 0.969139
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909707892508262
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9270104025490582 W std: 0.4720447211043069
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.050536
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974962	Recall: 0.963384F1: 0.969139
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909707892508262
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9270105278119445 W std: 0.47204472109957946
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.050536
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974962	Recall: 0.963384F1: 0.969139
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909707892508262
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -0.9270105278119445 W std: 0.47204472109957946
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.050536
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993661	Recall: 0.994065F1: 0.993863
Neg Count: 2	N Samples: 1718	Precision: 0.978700	Recall: 0.962514	F1: 0.970539
Neg Count: 1	N Samples: 12655	Precision: 0.974962	Recall: 0.963384F1: 0.969139
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
overall f1: 0.9909707892508262
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_2_wordEmbd_0_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 2
word embd: 0
char embd: 1
[dynet] random seed: 2
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -4.569457218050957 W std: 0.22415494179833798
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.183035
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.969762	Recall: 0.971654F1: 0.970707
Neg Count: 2	N Samples: 1718	Precision: 0.937576	Recall: 0.844542	F1: 0.888631
Neg Count: 1	N Samples: 12655	Precision: 0.882263	Recall: 0.856507F1: 0.869194
Neg Count: 4	N Samples: 14	Precision: 0.750000	Recall: 0.666667	F1: 0.705882
Neg Count: 3	N Samples: 168	Precision: 0.939759	Recall: 0.917647	F1: 0.928571
overall f1: 0.9592233937121637
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -13.709016202716157 W std: 0.5101861362738628
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.076404
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.989716	Recall: 0.988401F1: 0.989058
Neg Count: 2	N Samples: 1718	Precision: 0.972603	Recall: 0.939361	F1: 0.955693
Neg Count: 1	N Samples: 12655	Precision: 0.949962	Recall: 0.939386F1: 0.944645
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.984038298532765
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.305540552501043 W std: 0.5667129736314823
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.058317
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993054	Recall: 0.991897F1: 0.992475
Neg Count: 2	N Samples: 1718	Precision: 0.979475	Recall: 0.947078	F1: 0.963004
Neg Count: 1	N Samples: 12655	Precision: 0.966917	Recall: 0.954478F1: 0.960657
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9887541187144835
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.281706315930933 W std: 0.5732291899078932
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.056892
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993381	Recall: 0.992439F1: 0.992910
Neg Count: 2	N Samples: 1718	Precision: 0.979499	Recall: 0.948181	F1: 0.963585
Neg Count: 1	N Samples: 12655	Precision: 0.968664	Recall: 0.955962F1: 0.962271
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9893043021534641
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.272028888575733 W std: 0.5737428444018563
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.056378
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993409	Recall: 0.992602F1: 0.993005
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968915	Recall: 0.956210F1: 0.962520
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894244312349304
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.269045457942411 W std: 0.5737190430476345
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.056280
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993383	Recall: 0.992629F1: 0.993006
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968680	Recall: 0.956457F1: 0.962530
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894249361438018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.269162106793374 W std: 0.5737181061380963
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.056273
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993383	Recall: 0.992629F1: 0.993006
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968680	Recall: 0.956457F1: 0.962530
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894249361438018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.269167689606547 W std: 0.5737181037564719
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.056273
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993383	Recall: 0.992629F1: 0.993006
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968680	Recall: 0.956457F1: 0.962530
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894249361438018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.269167559687048 W std: 0.5737181037883166
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.056273
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993383	Recall: 0.992629F1: 0.993006
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968680	Recall: 0.956457F1: 0.962530
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894249361438018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -14.269167559687048 W std: 0.5737181037883166
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.056273
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.993383	Recall: 0.992629F1: 0.993006
Neg Count: 2	N Samples: 1718	Precision: 0.979522	Recall: 0.949283	F1: 0.964166
Neg Count: 1	N Samples: 12655	Precision: 0.968680	Recall: 0.956457F1: 0.962530
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
Neg Count: 3	N Samples: 168	Precision: 0.965116	Recall: 0.976471	F1: 0.970760
overall f1: 0.9894249361438018
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_2_wordEmbd_0_charEmbd_1.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 2
word embd: 1
char embd: 0
[dynet] random seed: 2
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -1.6335192173719406 W std: 0.21877826115030077
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.319852
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.940227	Recall: 0.940788F1: 0.940507
Neg Count: 2	N Samples: 1718	Precision: 0.888305	Recall: 0.745314	F1: 0.810552
Neg Count: 1	N Samples: 12655	Precision: 0.744691	Recall: 0.746165F1: 0.745428
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.666667	F1: 0.800000
Neg Count: 3	N Samples: 168	Precision: 0.867470	Recall: 0.847059	F1: 0.857143
overall f1: 0.9188821373571932
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.3621098989387974 W std: 0.3405386552823684
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.243467
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.954893	Recall: 0.955746F1: 0.955319
Neg Count: 2	N Samples: 1718	Precision: 0.905048	Recall: 0.830209	F1: 0.866015
Neg Count: 1	N Samples: 12655	Precision: 0.820407	Recall: 0.837457F1: 0.828844
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.894118	Recall: 0.894118	F1: 0.894118
overall f1: 0.9410208750357449
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.4754229076206684 W std: 0.349537593685883
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.224034
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.958477	Recall: 0.962711F1: 0.960589
Neg Count: 2	N Samples: 1718	Precision: 0.908343	Recall: 0.852260	F1: 0.879408
Neg Count: 1	N Samples: 12655	Precision: 0.831937	Recall: 0.859723F1: 0.845602
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9475548581889071
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.45729484158800915 W std: 0.35160303793395425
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.221665
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959144	Recall: 0.963199F1: 0.961167
Neg Count: 2	N Samples: 1718	Precision: 0.908665	Recall: 0.855568	F1: 0.881317
Neg Count: 1	N Samples: 12655	Precision: 0.834051	Recall: 0.862939F1: 0.848249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9483518965373781
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.46261384832905605 W std: 0.35173471800720235
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.220951
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959108	Recall: 0.963578F1: 0.961338
Neg Count: 2	N Samples: 1718	Precision: 0.908665	Recall: 0.855568	F1: 0.881317
Neg Count: 1	N Samples: 12655	Precision: 0.834250	Recall: 0.862939F1: 0.848352
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485156045732215
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.46019129297928885 W std: 0.3517031461597807
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.220721
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959110	Recall: 0.963632F1: 0.961366
Neg Count: 2	N Samples: 1718	Precision: 0.907494	Recall: 0.854465	F1: 0.880182
Neg Count: 1	N Samples: 12655	Precision: 0.834450	Recall: 0.862939F1: 0.848455
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485281009709661
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.4604860302642919 W std: 0.35170094843706284
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.220708
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959110	Recall: 0.963632F1: 0.961366
Neg Count: 2	N Samples: 1718	Precision: 0.907494	Recall: 0.854465	F1: 0.880182
Neg Count: 1	N Samples: 12655	Precision: 0.834450	Recall: 0.862939F1: 0.848455
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485281009709661
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.4604569568182342 W std: 0.3517009464002074
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.220707
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959110	Recall: 0.963632F1: 0.961366
Neg Count: 2	N Samples: 1718	Precision: 0.907494	Recall: 0.854465	F1: 0.880182
Neg Count: 1	N Samples: 12655	Precision: 0.834450	Recall: 0.862939F1: 0.848455
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485281009709661
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.4604579986189492 W std: 0.3517009463939254
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.220707
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959110	Recall: 0.963632F1: 0.961366
Neg Count: 2	N Samples: 1718	Precision: 0.907494	Recall: 0.854465	F1: 0.880182
Neg Count: 1	N Samples: 12655	Precision: 0.834450	Recall: 0.862939F1: 0.848455
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485281009709661
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: 0.4604579986189492 W std: 0.3517009463939254
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.220707
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959110	Recall: 0.963632F1: 0.961366
Neg Count: 2	N Samples: 1718	Precision: 0.907494	Recall: 0.854465	F1: 0.880182
Neg Count: 1	N Samples: 12655	Precision: 0.834450	Recall: 0.862939F1: 0.848455
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.927711	Recall: 0.905882	F1: 0.916667
overall f1: 0.9485281009709661
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_2_wordEmbd_1_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 2
word embd: 1
char embd: 1
[dynet] random seed: 2
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -1.6335192173719406 W std: 0.21877826115030077
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.297059
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.938259	Recall: 0.961600F1: 0.949786
Neg Count: 2	N Samples: 1718	Precision: 0.881356	Recall: 0.745314	F1: 0.807646
Neg Count: 1	N Samples: 12655	Precision: 0.748346	Recall: 0.783523F1: 0.765531
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
Neg Count: 3	N Samples: 168	Precision: 0.860759	Recall: 0.800000	F1: 0.829268
overall f1: 0.9287557896969911
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.478909022640437 W std: 0.34965448277296907
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.226254
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.959654	Recall: 0.960435F1: 0.960044
Neg Count: 2	N Samples: 1718	Precision: 0.902948	Recall: 0.810364	F1: 0.854155
Neg Count: 1	N Samples: 12655	Precision: 0.829681	Recall: 0.824344F1: 0.827004
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
overall f1: 0.9448760636330004
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.540413018345134 W std: 0.36902494526604396
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.207932
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.963746	Recall: 0.963876F1: 0.963811
Neg Count: 2	N Samples: 1718	Precision: 0.917973	Recall: 0.839030	F1: 0.876728
Neg Count: 1	N Samples: 12655	Precision: 0.848014	Recall: 0.850322F1: 0.849166
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9507754712479123
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.4877803267445415 W std: 0.3706517716192937
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.205963
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964119	Recall: 0.964093F1: 0.964106
Neg Count: 2	N Samples: 1718	Precision: 0.917973	Recall: 0.839030	F1: 0.876728
Neg Count: 1	N Samples: 12655	Precision: 0.850419	Recall: 0.853785F1: 0.852099
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9513117550913277
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.482908024219796 W std: 0.37082974449952116
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.205558
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964030	Recall: 0.964527F1: 0.964278
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850812	Recall: 0.855022F1: 0.852912
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515528839272935
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.480379136046395 W std: 0.3707428227779183
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.205407
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964031	Recall: 0.964554F1: 0.964292
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850603	Recall: 0.855022F1: 0.852807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515540395486964
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.4808116087224334 W std: 0.37074082314059487
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.205394
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964031	Recall: 0.964554F1: 0.964292
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850603	Recall: 0.855022F1: 0.852807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515540395486964
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.480777588672936 W std: 0.37074082775629563
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.205394
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964031	Recall: 0.964554F1: 0.964292
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850603	Recall: 0.855022F1: 0.852807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515540395486964
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.480777500197291 W std: 0.37074082776997747
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.205394
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964031	Recall: 0.964554F1: 0.964292
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850603	Recall: 0.855022F1: 0.852807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515540395486964
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
W sum: -4.480777500197291 W std: 0.37074082776997747
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.205394
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.964031	Recall: 0.964554F1: 0.964292
Neg Count: 2	N Samples: 1718	Precision: 0.918072	Recall: 0.840132	F1: 0.877375
Neg Count: 1	N Samples: 12655	Precision: 0.850603	Recall: 0.855022F1: 0.852807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.777778	F1: 0.875000
Neg Count: 3	N Samples: 168	Precision: 0.913580	Recall: 0.870588	F1: 0.891566
overall f1: 0.9515540395486964
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_2_wordEmbd_1_charEmbd_1.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 3
word embd: 0
char embd: 0
[dynet] random seed: 3
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -2.7010245621204376 W std: 0.2253215357855791
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.185494
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.865008	Recall: 0.886195F1: 0.875474
Neg Count: 0	N Samples: 44997	Precision: 0.966822	Recall: 0.967372F1: 0.967097
Neg Count: 2	N Samples: 1718	Precision: 0.921205	Recall: 0.876516	F1: 0.898305
Neg Count: 3	N Samples: 168	Precision: 0.896552	Recall: 0.917647	F1: 0.906977
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9565776623871568
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.4052936256630346 W std: 0.45852509552370413
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.075114
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.955467	Recall: 0.944829F1: 0.950118
Neg Count: 0	N Samples: 44997	Precision: 0.988814	Recall: 0.989323F1: 0.989068
Neg Count: 2	N Samples: 1718	Precision: 0.978186	Recall: 0.939361	F1: 0.958380
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9846704443781688
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.18967703304952 W std: 0.5088753149009501
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.057249
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969062	Recall: 0.960910F1: 0.964969
Neg Count: 0	N Samples: 44997	Precision: 0.992201	Recall: 0.992981F1: 0.992591
Neg Count: 2	N Samples: 1718	Precision: 0.984018	Recall: 0.950386	F1: 0.966910
Neg Count: 3	N Samples: 168	Precision: 0.988095	Recall: 0.976471	F1: 0.982249
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9893740086582152
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.21888929232955 W std: 0.514042846925145
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.055359
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972236	Recall: 0.961653F1: 0.966915
Neg Count: 0	N Samples: 44997	Precision: 0.992820	Recall: 0.993008F1: 0.992914
Neg Count: 2	N Samples: 1718	Precision: 0.986317	Recall: 0.953693	F1: 0.969731
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9899187535045753
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.218126794323325 W std: 0.5144461757538327
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.054941
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.2140129287727177 W std: 0.5144147770503201
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.054852
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.2144422533456236 W std: 0.5144134618609655
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.054846
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.214452563552186 W std: 0.5144134601654051
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.054846
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.2144525239709765 W std: 0.5144134601663732
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.054846
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -2.2144525239709765 W std: 0.5144134601663732
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.054846
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.972479	Recall: 0.961653F1: 0.967036
Neg Count: 0	N Samples: 44997	Precision: 0.993062	Recall: 0.992927F1: 0.992994
Neg Count: 2	N Samples: 1718	Precision: 0.986333	Recall: 0.954796	F1: 0.970308
Neg Count: 3	N Samples: 168	Precision: 1.000000	Recall: 0.976471	F1: 0.988095
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9900127674299283
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_3_wordEmbd_0_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 3
word embd: 0
char embd: 1
[dynet] random seed: 3
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -2.7010245621204376 W std: 0.2253215357855791
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.184974
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.853879	Recall: 0.887679F1: 0.870451
Neg Count: 0	N Samples: 44997	Precision: 0.964964	Recall: 0.969540F1: 0.967247
Neg Count: 2	N Samples: 1718	Precision: 0.926230	Recall: 0.872106	F1: 0.898353
Neg Count: 3	N Samples: 168	Precision: 0.873563	Recall: 0.894118	F1: 0.883721
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9561487923394043
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -8.133694886782905 W std: 0.5051958868322739
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.082348
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.948859	Recall: 0.936418F1: 0.942597
Neg Count: 0	N Samples: 44997	Precision: 0.988241	Recall: 0.988401F1: 0.988321
Neg Count: 2	N Samples: 1718	Precision: 0.971461	Recall: 0.938258	F1: 0.954571
Neg Count: 3	N Samples: 168	Precision: 0.975309	Recall: 0.929412	F1: 0.951807
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.98313943082155
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.647221525374334 W std: 0.5784833961973034
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.063319
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.967604	Recall: 0.953241F1: 0.960369
Neg Count: 0	N Samples: 44997	Precision: 0.991928	Recall: 0.992385F1: 0.992156
Neg Count: 2	N Samples: 1718	Precision: 0.980747	Recall: 0.954796	F1: 0.967598
Neg Count: 3	N Samples: 168	Precision: 0.987500	Recall: 0.929412	F1: 0.957576
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.988522477808533
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.54007678932976 W std: 0.5856481664040896
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.061092
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.968915	Recall: 0.956210F1: 0.962520
Neg Count: 0	N Samples: 44997	Precision: 0.992280	Recall: 0.992710F1: 0.992495
Neg Count: 2	N Samples: 1718	Precision: 0.983032	Recall: 0.958104	F1: 0.970408
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9890962015651842
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.540181718577514 W std: 0.5863115453995136
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.060601
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992495	Recall: 0.992710F1: 0.992603
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892142124227455
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.542514940883848 W std: 0.5863156986338619
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.060501
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992522	Recall: 0.992764F1: 0.992643
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892501342241843
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.542513690095802 W std: 0.5863154116815193
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.060494
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992522	Recall: 0.992764F1: 0.992643
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892501342241843
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.542509058890573 W std: 0.586315411978
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.060494
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992522	Recall: 0.992764F1: 0.992643
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892501342241843
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.542509278122452 W std: 0.5863154119289655
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.060494
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992522	Recall: 0.992764F1: 0.992643
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892501342241843
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -10.542509254693869 W std: 0.5863154119333572
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.060494
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.969157	Recall: 0.956210F1: 0.962640
Neg Count: 0	N Samples: 44997	Precision: 0.992522	Recall: 0.992764F1: 0.992643
Neg Count: 2	N Samples: 1718	Precision: 0.984145	Recall: 0.958104	F1: 0.970950
Neg Count: 3	N Samples: 168	Precision: 0.987654	Recall: 0.941176	F1: 0.963855
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 1.000000	F1: 1.000000
overall f1: 0.9892501342241843
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_3_wordEmbd_0_charEmbd_1.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 3
word embd: 1
char embd: 0
[dynet] random seed: 3
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -0.13930992782115936 W std: 0.215285202358138
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.318383
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.721191	Recall: 0.778822F1: 0.748900
Neg Count: 0	N Samples: 44997	Precision: 0.935909	Recall: 0.947373F1: 0.941606
Neg Count: 2	N Samples: 1718	Precision: 0.859734	Recall: 0.783903	F1: 0.820069
Neg Count: 3	N Samples: 168	Precision: 0.827160	Recall: 0.788235	F1: 0.807229
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9196845552678561
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.323616536683403 W std: 0.39962817799235284
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.242540
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.789977	Recall: 0.838446F1: 0.813490
Neg Count: 0	N Samples: 44997	Precision: 0.952558	Recall: 0.963090F1: 0.957795
Neg Count: 2	N Samples: 1718	Precision: 0.895906	Recall: 0.844542	F1: 0.869467
Neg Count: 3	N Samples: 168	Precision: 0.867470	Recall: 0.847059	F1: 0.857143
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9415078707539354
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.6492166091993568 W std: 0.4254884847813475
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.219592
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.825301	Recall: 0.847353F1: 0.836182
Neg Count: 0	N Samples: 44997	Precision: 0.957751	Recall: 0.967562F1: 0.962631
Neg Count: 2	N Samples: 1718	Precision: 0.913712	Recall: 0.852260	F1: 0.881917
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9484746406035014
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7398490474442951 W std: 0.4299995129809761
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.216443
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.829705	Recall: 0.848590F1: 0.839041
Neg Count: 0	N Samples: 44997	Precision: 0.958545	Recall: 0.968104F1: 0.963301
Neg Count: 2	N Samples: 1718	Precision: 0.917258	Recall: 0.855568	F1: 0.885339
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494316698701978
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7481338063953444 W std: 0.43036306931061086
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.216142
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.830870	Recall: 0.848342F1: 0.839515
Neg Count: 0	N Samples: 44997	Precision: 0.958620	Recall: 0.968050F1: 0.963312
Neg Count: 2	N Samples: 1718	Precision: 0.917258	Recall: 0.855568	F1: 0.885339
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494956686839918
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.750569089083001 W std: 0.4302651417945449
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.215960
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.831150	Recall: 0.847600F1: 0.839294
Neg Count: 0	N Samples: 44997	Precision: 0.958671	Recall: 0.968050F1: 0.963338
Neg Count: 2	N Samples: 1718	Precision: 0.917160	Recall: 0.854465	F1: 0.884703
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494908737034486
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7502230087993667 W std: 0.43026411982653295
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.215949
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.831109	Recall: 0.847353F1: 0.839152
Neg Count: 0	N Samples: 44997	Precision: 0.958671	Recall: 0.968050F1: 0.963338
Neg Count: 2	N Samples: 1718	Precision: 0.917160	Recall: 0.854465	F1: 0.884703
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494784063801759
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7502256341977045 W std: 0.430264117970538
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.215949
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.831109	Recall: 0.847353F1: 0.839152
Neg Count: 0	N Samples: 44997	Precision: 0.958671	Recall: 0.968050F1: 0.963338
Neg Count: 2	N Samples: 1718	Precision: 0.917160	Recall: 0.854465	F1: 0.884703
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494784063801759
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7502266073133796 W std: 0.43026411791017777
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.215949
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.831109	Recall: 0.847353F1: 0.839152
Neg Count: 0	N Samples: 44997	Precision: 0.958671	Recall: 0.968050F1: 0.963338
Neg Count: 2	N Samples: 1718	Precision: 0.917160	Recall: 0.854465	F1: 0.884703
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494784063801759
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: -1.7502266073133796 W std: 0.43026411791017777
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.215949
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.831109	Recall: 0.847353F1: 0.839152
Neg Count: 0	N Samples: 44997	Precision: 0.958671	Recall: 0.968050F1: 0.963338
Neg Count: 2	N Samples: 1718	Precision: 0.917160	Recall: 0.854465	F1: 0.884703
Neg Count: 3	N Samples: 168	Precision: 0.888889	Recall: 0.847059	F1: 0.867470
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9494784063801759
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 193, in main
    np.savetxt(file_name, f1_results, delimiter=',')
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py", line 1317, in savetxt
    open(fname, 'wt').close()
FileNotFoundError: [Errno 2] No such file or directory: 'Result/f1_score_seed_3_wordEmbd_1_charEmbd_0.csv'
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
python random seed: 3
word embd: 1
char embd: 1
[dynet] random seed: 3
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: -0.13930992782115936 W std: 0.215285202358138
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.300100
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.725904	Recall: 0.799357F1: 0.760862
Neg Count: 0	N Samples: 44997	Precision: 0.938340	Recall: 0.952224F1: 0.945231
Neg Count: 2	N Samples: 1718	Precision: 0.857639	Recall: 0.816979	F1: 0.836815
Neg Count: 3	N Samples: 168	Precision: 0.818182	Recall: 0.847059	F1: 0.832370
Neg Count: 4	N Samples: 14	Precision: 1.000000	Recall: 0.888889	F1: 0.941176
overall f1: 0.9242706539940095
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 1.5975366411730647 W std: 0.3793124307326953
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.235962
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.785850	Recall: 0.818902F1: 0.802035
Neg Count: 0	N Samples: 44997	Precision: 0.953197	Recall: 0.964202F1: 0.958668
Neg Count: 2	N Samples: 1718	Precision: 0.892774	Recall: 0.844542	F1: 0.867989
Neg Count: 3	N Samples: 168	Precision: 0.867470	Recall: 0.847059	F1: 0.857143
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9412308129619101
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.8047824327950366 W std: 0.40842376625404125
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.220979
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.810332	Recall: 0.826571F1: 0.818371
Neg Count: 0	N Samples: 44997	Precision: 0.959019	Recall: 0.966478F1: 0.962734
Neg Count: 2	N Samples: 1718	Precision: 0.904706	Recall: 0.847850	F1: 0.875356
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.946695805026367
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6686907617840916 W std: 0.411740328309242
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.218886
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.811716	Recall: 0.833003F1: 0.822222
Neg Count: 0	N Samples: 44997	Precision: 0.959341	Recall: 0.967426F1: 0.963367
Neg Count: 2	N Samples: 1718	Precision: 0.902212	Recall: 0.854465	F1: 0.877690
Neg Count: 3	N Samples: 168	Precision: 0.869048	Recall: 0.858824	F1: 0.863905
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9476357766805925
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6519987736828625 W std: 0.4120408956580097
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.218201
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.813453	Recall: 0.831766F1: 0.822508
Neg Count: 0	N Samples: 44997	Precision: 0.959444	Recall: 0.967426F1: 0.963419
Neg Count: 2	N Samples: 1718	Precision: 0.903263	Recall: 0.854465	F1: 0.878187
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9477408172471923
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6523766652680933 W std: 0.4119112590767377
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.217983
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.813604	Recall: 0.831519F1: 0.822464
Neg Count: 0	N Samples: 44997	Precision: 0.959444	Recall: 0.967426F1: 0.963419
Neg Count: 2	N Samples: 1718	Precision: 0.903263	Recall: 0.854465	F1: 0.878187
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9477395764080159
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6525724977254868 W std: 0.41190974820957016
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.217970
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.813604	Recall: 0.831519F1: 0.822464
Neg Count: 0	N Samples: 44997	Precision: 0.959444	Recall: 0.967426F1: 0.963419
Neg Count: 2	N Samples: 1718	Precision: 0.903263	Recall: 0.854465	F1: 0.878187
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9477395764080159
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6525685742963105 W std: 0.4119097464182598
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.217970
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.813604	Recall: 0.831519F1: 0.822464
Neg Count: 0	N Samples: 44997	Precision: 0.959444	Recall: 0.967426F1: 0.963419
Neg Count: 2	N Samples: 1718	Precision: 0.903263	Recall: 0.854465	F1: 0.878187
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9477395764080159
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6525685775559396 W std: 0.4119097464181467
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.217970
---------------LSTM result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.813604	Recall: 0.831519F1: 0.822464
Neg Count: 0	N Samples: 44997	Precision: 0.959444	Recall: 0.967426F1: 0.963419
Neg Count: 2	N Samples: 1718	Precision: 0.903263	Recall: 0.854465	F1: 0.878187
Neg Count: 3	N Samples: 168	Precision: 0.879518	Recall: 0.858824	F1: 0.869048
Neg Count: 4	N Samples: 14	Precision: 0.875000	Recall: 0.777778	F1: 0.823529
overall f1: 0.9477395764080159
---------------REACH result------------------------- 
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536F1: 0.488398
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137F1: 0.909382
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 0.6525685775559396 W std: 0.4119097464181467
learning rate: 1.0000001044244144e-12
^A^A^CTraceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 108, in main
    prediction = run_instance(instance, elements, embeddings_index, embeddings_char_index, char_embd_sel)
  File "/lhome/zhengzhongliang/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity/rnn.py", line 82, in run_instance
    char_embd = get_char_embd(word, model_elems, char_embeddings)
  File "/lhome/zhengzhongliang/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity/rnn.py", line 27, in get_char_embd
    output_fwd = gru_char_fwd.transduce(char_embd_list)
KeyboardInterrupt
/lhome/zhengzhongliang/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
^Apython random seed: 4
word embd: 0
char embd: 0
[dynet] random seed: 4
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
^C^CTraceback (most recent call last):
  File "/lhome/zhengzhongliang/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity/w2v.py", line 34, in load_embeddings
    raw = pickle.load(f)
  File "/lhome/zhengzhongliang/anaconda3/lib/python3.6/gzip.py", line 291, in peek
    def peek(self, n):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training.py", line 199, in <module>
    main("SentencesInfo_all_label_final.csv")
  File "training.py", line 39, in main
    embeddings = w2v.load_embeddings("/lhome/zhengzhongliang/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20181015/w2v/pubmed/medPubDict.pkl.gz")
  File "/lhome/zhengzhongliang/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity/w2v.py", line 34, in load_embeddings
    raw = pickle.load(f)
KeyboardInterrupt
^C
zhengzhongliang@dauphin:~/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity$ ^C
zhengzhongliang@dauphin:~/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity$ ^C
zhengzhongliang@dauphin:~/CLU_Projects/2018_Automated_Scientific_Discovery_Framework/polarity/20190129/lstm_polarity$ 

