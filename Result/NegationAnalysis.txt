python random seed: 1
[dynet] random seed: 1
[dynet] allocating memory: 512MB
[dynet] memory allocation done.
There are 59552 rows
There are 59552 instances
W sum: 3.3909694850444794 W std: 0.16412384082247725
learning rate: 0.0010000000474974513
W sum: -3.8856475055217743 W std: 0.1676785202507452
learning rate: 0.0010000000474974513
W sum: 4.324834108352661 W std: 0.16768901402316608
learning rate: 0.0010000000474974513
W sum: -5.489519074559212 W std: 0.1693163479312437
learning rate: 0.0010000000474974513
W sum: -1.9956523776054382 W std: 0.16544965906353318
learning rate: 0.0010000000474974513
===================================================================
number of bad grads: 0
Epoch 1 average training loss: 0.194256
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.974132	Recall: 0.97967F1: 0.976896
Neg Count: 1	N Samples: 12655	Precision: 0.881929	Recall: 0.90920F1: 0.895359
Neg Count: 2	N Samples: 1718	Precision: 0.926471	Recall: 0.902977	F1: 0.914573
Neg Count: 3	N Samples: 168	Precision: 0.938272	Recall: 0.894118	F1: 0.915663
Neg Count: 4	N Samples: 14	Precision: 0.800000	Recall: 0.888889	F1: 0.842105
overall f1: 0.9674691497321758
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.94013F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.37753F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.021076224860735 W std: 0.234003480093886
learning rate: 0.00010000000474974513
W sum: -9.60549853532575 W std: 0.2340917877484339
learning rate: 0.00010000000474974513
W sum: 6.08745243010344 W std: 0.23937015189256358
learning rate: 0.00010000000474974513
W sum: -5.8379407689208165 W std: 0.24236859374124128
learning rate: 0.00010000000474974513
W sum: -1.922577767050825 W std: 0.23094726959260806
learning rate: 0.00010000000474974513
===================================================================
number of bad grads: 0
Epoch 2 average training loss: 0.102735
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978119	Recall: 0.982440	F1: 0.980274
Neg Count: 1	N Samples: 12655	Precision: 0.905845	Recall: 0.916378	F1: 0.911081
Neg Count: 2	N Samples: 1718	Precision: 0.939121	Recall: 0.918412	F1: 0.928651
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9723576848966388
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.043350053412723 W std: 0.25026793910708034
learning rate: 1.0000000656873453e-05
W sum: -10.18284912974923 W std: 0.24916684366750103
learning rate: 1.0000000656873453e-05
W sum: 5.918927639559115 W std: 0.2562567803975879
learning rate: 1.0000000656873453e-05
W sum: -5.827970830054255 W std: 0.25486826528174683
learning rate: 1.0000000656873453e-05
W sum: -1.4638856525998563 W std: 0.24721130442591385
learning rate: 1.0000000656873453e-05
===================================================================
number of bad grads: 0
Epoch 3 average training loss: 0.092329
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978767	Recall: 0.981870	F1: 0.980316
Neg Count: 1	N Samples: 12655	Precision: 0.909584	Recall: 0.913409	F1: 0.911492
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.972487112634975
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.05436802119948 W std: 0.25135843984449185
learning rate: 1.0000001111620804e-06
W sum: -10.21148525213357 W std: 0.25088716525414845
learning rate: 1.0000001111620804e-06
W sum: 5.86751034061308 W std: 0.2578347480228386
learning rate: 1.0000001111620804e-06
W sum: -5.8279140628292225 W std: 0.2560993768305198
learning rate: 1.0000001111620804e-06
W sum: -1.4637304276693612 W std: 0.24801181530555613
learning rate: 1.0000001111620804e-06
===================================================================
number of bad grads: 0
Epoch 4 average training loss: 0.090921
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.05448213769705 W std: 0.2514676753671913
learning rate: 1.000000082740371e-07
W sum: -10.214187029690947 W std: 0.2510368851679525
learning rate: 1.000000082740371e-07
W sum: 5.8699960114481655 W std: 0.25795953037561425
learning rate: 1.000000082740371e-07
W sum: -5.827737185463775 W std: 0.25623210758909815
learning rate: 1.000000082740371e-07
W sum: -1.4636773036327213 W std: 0.24810654022936401
learning rate: 1.000000082740371e-07
===================================================================
number of bad grads: 0
Epoch 5 average training loss: 0.090776
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.054460950312205 W std: 0.251465057685533
learning rate: 1.000000082740371e-08
W sum: -10.21356429363368 W std: 0.25103737955082095
learning rate: 1.000000082740371e-08
W sum: 5.870128099178601 W std: 0.25795733764239964
learning rate: 1.000000082740371e-08
W sum: -5.827096282708226 W std: 0.25623051282614795
learning rate: 1.000000082740371e-08
W sum: -1.4635399950202554 W std: 0.24810114215752782
learning rate: 1.000000082740371e-08
===================================================================
number of bad grads: 0
Epoch 6 average training loss: 0.090748
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.054563344543567 W std: 0.25146471141613586
learning rate: 1.000000082740371e-09
W sum: -10.213618711481104 W std: 0.25103689915667954
learning rate: 1.000000082740371e-09
W sum: 5.870112108132616 W std: 0.2579569618399843
learning rate: 1.000000082740371e-09
W sum: -5.827115541367675 W std: 0.2562300541529297
learning rate: 1.000000082740371e-09
W sum: -1.4635770737659186 W std: 0.24810065425857833
learning rate: 1.000000082740371e-09
===================================================================
number of bad grads: 0
Epoch 7 average training loss: 0.090746
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.054566078615608 W std: 0.25146471146464067
learning rate: 1.000000082740371e-10
W sum: -10.213619279762497 W std: 0.2510368990555063
learning rate: 1.000000082740371e-10
W sum: 5.8701167530207385 W std: 0.2579569617940746
learning rate: 1.000000082740371e-10
W sum: -5.827115108200815 W std: 0.2562300542831912
learning rate: 1.000000082740371e-10
W sum: -1.4635793919442222 W std: 0.24810065454082522
learning rate: 1.000000082740371e-10
===================================================================
number of bad grads: 0
Epoch 8 average training loss: 0.090746
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.054566112667089 W std: 0.25146471146148597
learning rate: 1.000000082740371e-11
W sum: -10.21361909067491 W std: 0.25103689907774135
learning rate: 1.000000082740371e-11
W sum: 5.870116758233053 W std: 0.25795696179309047
learning rate: 1.000000082740371e-11
W sum: -5.827115087886341 W std: 0.25623005428512013
learning rate: 1.000000082740371e-11
W sum: -1.463579463888891 W std: 0.2481006545389273
learning rate: 1.000000082740371e-11
===================================================================
number of bad grads: 0
Epoch 9 average training loss: 0.090746
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
W sum: 6.0545661126379855 W std: 0.25146471146148797
learning rate: 1.0000001044244144e-12
W sum: -10.21361909020925 W std: 0.2510368990777909
learning rate: 1.0000001044244144e-12
W sum: 5.870116756844254 W std: 0.25795696179317534
learning rate: 1.0000001044244144e-12
W sum: -5.827115088075516 W std: 0.2562300542851083
learning rate: 1.0000001044244144e-12
W sum: -1.463579463888891 W std: 0.2481006545389273
learning rate: 1.0000001044244144e-12
===================================================================
number of bad grads: 0
Epoch 10 average training loss: 0.090746
---------------LSTM result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.978739	Recall: 0.981789	F1: 0.980262
Neg Count: 1	N Samples: 12655	Precision: 0.909561	Recall: 0.913162	F1: 0.911358
Neg Count: 2	N Samples: 1718	Precision: 0.941309	Recall: 0.919515	F1: 0.930284
Neg Count: 3	N Samples: 168	Precision: 0.950617	Recall: 0.905882	F1: 0.927711
Neg Count: 4	N Samples: 14	Precision: 0.888889	Recall: 0.888889	F1: 0.888889
overall f1: 0.9724266019001357
---------------REACH result------------------------- 
Neg Count: 0	N Samples: 44997	Precision: 0.880575	Recall: 0.940137	F1: 0.909382
Neg Count: 1	N Samples: 12655	Precision: 0.691436	Recall: 0.377536	F1: 0.488398
Neg Count: 2	N Samples: 1718	Precision: 0.758364	Recall: 0.674752	F1: 0.714119
Neg Count: 3	N Samples: 168	Precision: 0.700000	Recall: 0.658824	F1: 0.678788
Neg Count: 4	N Samples: 14	Precision: 0.500000	Recall: 0.333333	F1: 0.400000
overall f1: 0.8737224807854004
